"""
VBVA Ultra-Fast Processing Service
Implements aggressive optimizations to achieve sub-8-second processing for 9-second outputs
"""

import asyncio
import time
import tempfile
import os
import hashlib
import json
from typing import List, Dict, Optional, Tuple
from dataclasses import dataclass
import subprocess
import threading
from concurrent.futures import ThreadPoolExecutor
import httpx
import sys

from services.tts import TTSService
from services.lip_sync import LipSyncService

# Try to import enhanced TTS service
try:
    from services.enhanced_tts import EnhancedTTSService
    ENHANCED_TTS_AVAILABLE = True
except ImportError:
    ENHANCED_TTS_AVAILABLE = False
    print("‚ö†Ô∏è Enhanced TTS not available - using basic TTS")

@dataclass
class UltraProcessingStats:
    """Ultra-fast processing statistics"""
    total_chunks: int
    successful_chunks: int
    failed_chunks: int
    parallel_processing: bool
    chunk_duration: float
    total_processing_time: float
    audio_generation_time: float
    video_generation_time: float
    optimization_level: str
    speed_multiplier: float

class UltraFastProcessor:
    """Ultra-fast video processor with aggressive optimizations"""
    
    def __init__(self):
        # Use enhanced TTS service if available, otherwise fall back to basic TTS
        if ENHANCED_TTS_AVAILABLE:
            self.tts_service = EnhancedTTSService()
            print("üöÄ Using Enhanced TTS Service with fallback options")
        else:
            self.tts_service = TTSService()
            print("‚ö†Ô∏è Using Basic TTS Service")
        
        self.lip_sync_service = LipSyncService()
        
        # Ultra-fast configuration
        self.max_parallel_chunks = 8  # Maximum parallel processing
        self.optimal_chunk_duration = 6  # 6-second chunks for speed
        self.max_chunk_duration = 12  # Maximum chunk size
        
        # Performance optimizations
        self.enable_preprocessing = True
        self.enable_parallel_audio = True
        self.enable_memory_optimization = True
        self.enable_gpu_optimization = True
        
        # Cache configuration
        self.cache_dir = "/tmp/vbva_ultra_cache"
        os.makedirs(self.cache_dir, exist_ok=True)
        
        # Thread pool for parallel processing
        self.thread_pool = ThreadPoolExecutor(max_workers=8)
    
    async def process_video_ultra_fast(
        self,
        text: str,
        agent_type: str = "general",
        target_time: float = 8.0  # Target processing time in seconds
    ) -> Tuple[str, UltraProcessingStats]:
        """Process video with ultra-fast optimizations targeting sub-8-second processing"""
        
        start_time = time.time()
        
        try:
            # Step 1: Parallel audio generation with preprocessing
            audio_start = time.time()
            audio_url = await self._generate_audio_ultra_fast(text, agent_type)
            audio_time = time.time() - audio_start
            
            # Step 2: Ultra-fast video generation
            video_start = time.time()
            video_url = await self._generate_video_ultra_fast(audio_url, agent_type)
            video_time = time.time() - video_start
            
            total_time = time.time() - start_time
            speed_multiplier = 16.0 / total_time if total_time > 0 else 1.0  # 16s baseline
            
            # Create ultra processing stats
            stats = UltraProcessingStats(
                total_chunks=1,
                successful_chunks=1,
                failed_chunks=0,
                parallel_processing=True,
                chunk_duration=self.optimal_chunk_duration,
                total_processing_time=total_time,
                audio_generation_time=audio_time,
                video_generation_time=video_time,
                optimization_level="ultra_fast",
                speed_multiplier=speed_multiplier
            )
            
            print(f"üöÄ Ultra-fast processing completed in {total_time:.2f}s (target: {target_time:.1f}s)")
            print(f"üöÄ Speed multiplier: {speed_multiplier:.1f}x faster than baseline")
            
            return video_url, stats
            
        except Exception as e:
            total_time = time.time() - start_time
            raise Exception(f"Ultra-fast processing failed after {total_time:.2f}s: {str(e)}")
    
    async def _generate_audio_ultra_fast(self, text: str, agent_type: str) -> str:
        """Generate audio with ultra-fast optimizations"""
        
        # Temporarily disable caching to ensure fresh content
        # cache_key = self._get_audio_cache_key(text, agent_type)
        # cached_audio = await self._check_audio_cache(cache_key)
        # if cached_audio:
        #     print(f"üöÄ Using ultra-cached audio: {cached_audio}")
        #     return cached_audio
        
        # Generate audio with optimized settings
        audio_url = await self.tts_service.generate_speech(text, agent_type=agent_type)
        
        # Cache the result
        # await self._cache_audio(cache_key, audio_url)
        
        return audio_url
    
    async def _generate_video_ultra_fast(self, audio_url: str, agent_type: str) -> str:
        """Generate video with ultra-fast optimizations and robust looping prevention"""
        
        print(f"üé¨ Starting ultra-fast video generation for audio: {audio_url}")
        
        # Get audio duration
        audio_duration = await self._get_audio_duration_fast(audio_url)
        print(f"üéµ Audio duration: {audio_duration:.2f}s")
        
        # IMMEDIATE FIX: Force single video generation for ALL content to eliminate chunking issues
        print(f"üé¨ FORCING SINGLE VIDEO GENERATION for all content (eliminating chunking issues)")
        print(f"üé¨ This prevents any potential looping issues from chunking")
        video_url = await self._generate_single_video_ultra_fast(audio_url, agent_type)
        
        return video_url
    
    async def _generate_single_video_ultra_fast(self, audio_url: str, agent_type: str) -> str:
        """Generate single video with ultra-fast settings"""
        
        # Prepare files with minimal processing
        audio_path = await self._prepare_audio_ultra_fast(audio_url)
        avatar_path = await self._prepare_avatar_ultra_fast(agent_type)
        
        # Run Wav2Lip with ultra-fast parameters
        output_path = await self._run_wav2lip_ultra_fast(audio_path, avatar_path)
        
        # Convert to web-accessible URL
        video_url = await self._convert_to_web_format(output_path)
        
        return video_url
    
    async def _generate_single_video_local_ultra_fast(self, audio_url: str, agent_type: str) -> str:
        """Generate single video with ultra-fast settings and return local path (for chunk processing)"""
        
        # Prepare files with minimal processing
        audio_path = await self._prepare_audio_ultra_fast(audio_url)
        avatar_path = await self._prepare_avatar_ultra_fast(agent_type)
        
        # Run Wav2Lip with ultra-fast parameters
        output_path = await self._run_wav2lip_ultra_fast(audio_path, avatar_path)
        
        # Return local path for chunk processing
        return output_path
    
    async def _generate_parallel_video_ultra_fast(self, audio_url: str, agent_type: str) -> str:
        """Generate video with ultra-fast parallel processing and robust fallback"""
        
        print(f"üé¨ Starting parallel video generation with fallback protection")
        
        try:
            # Split audio into ultra-small chunks
            print(f"üéµ Splitting audio into chunks...")
            audio_chunks = await self._split_audio_ultra_fast(audio_url)
            print(f"‚úÖ Audio split into {len(audio_chunks)} chunks")
            
            # Validate chunks before processing
            if len(audio_chunks) <= 1:
                print(f"‚ö†Ô∏è Only {len(audio_chunks)} chunk(s) generated, falling back to single video")
                return await self._generate_single_video_ultra_fast(audio_url, agent_type)
            
            # Process chunks in parallel with maximum concurrency
            print(f"üé¨ Processing {len(audio_chunks)} chunks in parallel...")
            video_paths = await self._process_chunks_ultra_fast(audio_chunks, agent_type)
            print(f"‚úÖ Generated {len(video_paths)} video chunks")
            
            # Validate video chunks before combination
            if len(video_paths) != len(audio_chunks):
                print(f"‚ö†Ô∏è Video chunk mismatch! Expected {len(audio_chunks)}, got {len(video_paths)}")
                print(f"‚ö†Ô∏è Falling back to single video generation")
                return await self._generate_single_video_ultra_fast(audio_url, agent_type)
            
            # Validate video chunks for duplicates and invalid files
            validated_paths = await self._validate_video_chunks(video_paths)
            if len(validated_paths) != len(video_paths):
                print(f"‚ö†Ô∏è Video validation removed {len(video_paths) - len(validated_paths)} invalid chunks")
                if len(validated_paths) == 0:
                    print(f"‚ùå No valid video chunks after validation, falling back to single video")
                    return await self._generate_single_video_ultra_fast(audio_url, agent_type)
                video_paths = validated_paths
            
            # Combine videos with ultra-fast settings
            print(f"üé¨ Combining {len(video_paths)} video chunks...")
            combined_video_path = await self._combine_videos_with_improved_sync(video_paths)
            print(f"‚úÖ Video combination completed: {combined_video_path}")
            
            if not combined_video_path:
                print("‚ùå Video combination failed")
                return ""
            
            # Convert to web format with cache-busting
            web_url = await self._convert_to_web_format(combined_video_path)
            print(f"‚úÖ Final video URL: {web_url}")
            
            return web_url
            
        except Exception as e:
            print(f"‚ùå Parallel processing failed: {str(e)}")
            print(f"üîÑ Falling back to single video generation")
            return await self._generate_single_video_ultra_fast(audio_url, agent_type)
    
    async def _split_audio_ultra_fast(self, audio_path: str) -> List[str]:
        """Split audio into chunks with comprehensive debug logging"""
        try:
            print(f"üîç [DEBUG] Starting audio splitting for: {audio_path}")
            
            # Get audio duration
            audio_duration = await self._get_audio_duration_fast(audio_path)
            print(f"üîç [DEBUG] Audio duration: {audio_duration:.3f}s")
            
            # Determine chunking strategy
            if audio_duration <= 12:
                print(f"üîç [DEBUG] Audio ‚â§12s - using single chunk")
                return [audio_path]
            
            # Calculate chunk size and count
            chunk_duration = min(12, max(6, audio_duration / 2))
            num_chunks = int(audio_duration / chunk_duration) + (1 if audio_duration % chunk_duration > 0 else 0)
            
            print(f"üîç [DEBUG] Chunking strategy: {num_chunks} chunks of {chunk_duration:.1f}s each")
            
            # Create output directory
            output_dir = "/tmp/audio_chunks"
            os.makedirs(output_dir, exist_ok=True)
            
            # Split audio into chunks
            chunk_paths = []
            for i in range(num_chunks):
                start_time = i * chunk_duration
                end_time = min((i + 1) * chunk_duration, audio_duration)
                
                # Generate unique chunk filename
                chunk_filename = f"chunk_{i:03d}_{start_time:.1f}s_to_{end_time:.1f}s.mp3"
                chunk_path = os.path.join(output_dir, chunk_filename)
                
                print(f"üîç [DEBUG] Creating chunk {i+1}/{num_chunks}: {start_time:.1f}s - {end_time:.1f}s -> {chunk_path}")
                
                # Extract chunk using ffmpeg
                cmd = [
                    "ffmpeg",
                    "-i", audio_path,
                    "-ss", str(start_time),
                    "-t", str(end_time - start_time),
                    "-c:a", "mp3",
                    "-ar", "24000",
                    "-y",
                    chunk_path
                ]
                
                result = subprocess.run(cmd, capture_output=True, text=True)
                
                if result.returncode != 0:
                    print(f"‚ùå [DEBUG] Failed to create chunk {i+1}: {result.stderr}")
                    continue
                
                # Verify chunk exists and has content
                if os.path.exists(chunk_path) and os.path.getsize(chunk_path) > 1000:
                    chunk_duration_actual = await self._get_audio_duration_fast(chunk_path)
                    print(f"‚úÖ [DEBUG] Chunk {i+1} created: {chunk_path} (duration: {chunk_duration_actual:.3f}s)")
                    chunk_paths.append(chunk_path)
                else:
                    print(f"‚ùå [DEBUG] Chunk {i+1} validation failed: {chunk_path}")
            
            print(f"üîç [DEBUG] Audio splitting complete: {len(chunk_paths)} chunks created")
            for i, path in enumerate(chunk_paths):
                print(f"   Chunk {i+1}: {path}")
            
            return chunk_paths
            
        except Exception as e:
            print(f"‚ùå [DEBUG] Error splitting audio: {e}")
            return [audio_path]
    
    async def _process_chunks_ultra_fast(self, audio_chunks: List[str], agent_type: str) -> List[str]:
        """Process audio chunks in parallel with comprehensive debug logging"""
        if not audio_chunks:
            return []
        
        print(f"üîç [DEBUG] Starting parallel chunk processing: {len(audio_chunks)} chunks")
        
        # Process chunks in parallel
        async def process_single_chunk(chunk_path: str, chunk_index: int) -> (int, str):
            try:
                print(f"üîç [DEBUG] Processing chunk {chunk_index + 1}/{len(audio_chunks)}: {chunk_path}")
                
                # Get chunk duration for logging
                chunk_duration = await self._get_audio_duration_fast(chunk_path)
                print(f"üîç [DEBUG] Chunk {chunk_index + 1} duration: {chunk_duration:.3f}s")
                
                # Generate video for this chunk
                video_path = await self._generate_single_video_local_ultra_fast(chunk_path, agent_type)
                
                if video_path and os.path.exists(video_path):
                    video_size = os.path.getsize(video_path)
                    video_duration = await self._get_audio_duration_fast(video_path)
                    print(f"‚úÖ [DEBUG] Chunk {chunk_index + 1} video generated: {video_path}")
                    print(f"   Size: {video_size:,} bytes, Duration: {video_duration:.3f}s")
                    return chunk_index, video_path
                else:
                    print(f"‚ùå [DEBUG] Chunk {chunk_index + 1} video generation failed")
                    return chunk_index, ""
                    
            except Exception as e:
                print(f"‚ùå [DEBUG] Error processing chunk {chunk_index + 1}: {e}")
                return chunk_index, ""
        
        # Process all chunks
        tasks = [process_single_chunk(chunk, i) for i, chunk in enumerate(audio_chunks)]
        results = await asyncio.gather(*tasks)
        
        # Sort results by chunk index to preserve order
        results.sort(key=lambda x: x[0])
        video_paths = [result[1] for result in results if result[1]]
        
        print(f"üîç [DEBUG] Chunk processing complete: {len(video_paths)} videos generated")
        for i, path in enumerate(video_paths):
            print(f"   Video {i+1}: {path}")
        
        return video_paths
    
    async def _run_wav2lip_ultra_fast(self, audio_path: str, avatar_path: str) -> str:
        """Run Wav2Lip with ultra-fast parameters and improved synchronization"""
        
        # Create cache key with timestamp to prevent serving old cached videos
        with open(audio_path, 'rb') as f:
            audio_hash = hashlib.md5(f.read()).hexdigest()[:8]
        with open(avatar_path, 'rb') as f:
            avatar_hash = hashlib.md5(f.read()).hexdigest()[:8]
        
        # Add timestamp to make cache key unique for each request
        timestamp = str(int(time.time() * 1000))[-6:]  # Last 6 digits of timestamp
        cache_key = f"ultra_wav2lip_{audio_hash}_{avatar_hash}_{timestamp}"
        
        # Ultra-fast Wav2Lip command with improved synchronization
        wav2lip_dir = os.path.join(os.path.dirname(__file__), "..", "Wav2Lip")
        output_path = os.path.join("/tmp/wav2lip_ultra_outputs", f"{cache_key}.mp4")
        os.makedirs("/tmp/wav2lip_ultra_outputs", exist_ok=True)
        
        # Get audio duration to adjust parameters
        audio_duration = await self._get_audio_duration_fast(audio_path)
        
        # Adjust parameters based on audio duration for better synchronization
        if audio_duration <= 4:
            fps = 10  # Lower FPS for very short content
            batch_size = 32
        elif audio_duration <= 8:
            fps = 10  # Standard FPS for short content
            batch_size = 64
        else:
            fps = 10  # Consistent FPS for longer content
            batch_size = 64
        
        # STEP 1: Create a video from the static avatar image
        avatar_video_path = os.path.join("/tmp/wav2lip_ultra_outputs", f"avatar_video_{timestamp}.mp4")
        
        # Create a video with the static image repeated for the audio duration
        avatar_cmd = [
            "ffmpeg",
            "-loop", "1",  # Loop the input image
            "-i", avatar_path,
            "-c:v", "libx264",
            "-t", str(audio_duration),  # Set duration to match audio
            "-pix_fmt", "yuv420p",
            "-vf", "scale=480:480",  # Resize to standard size
            "-r", str(fps),  # Set frame rate
            "-avoid_negative_ts", "make_zero",  # Fix timestamp issues
            "-fflags", "+genpts",  # Generate proper timestamps
            avatar_video_path,
            "-y"
        ]
        
        print(f"üé¨ Creating avatar video: {' '.join(avatar_cmd)}")
        
        avatar_result = subprocess.run(avatar_cmd, capture_output=True, text=True)
        if avatar_result.returncode != 0:
            print(f"‚ùå Avatar video creation failed: {avatar_result.stderr}")
            raise Exception("Avatar video creation failed")
        
        print(f"‚úÖ Avatar video created: {avatar_video_path}")
        
        # STEP 2: Run Wav2Lip with the avatar video (not static image)
        cmd = [
            "python", "inference.py",
            "--checkpoint_path", "checkpoints/wav2lip.pth",
            "--face", avatar_video_path,  # Use video instead of static image
            "--audio", audio_path,
            "--outfile", output_path,
            "--fps", str(fps),  # Consistent FPS for better sync
            "--resize_factor", "6",  # Maximum resize for speed
            "--pads", "0", "2", "0", "0",  # Minimal padding
            "--wav2lip_batch_size", str(batch_size),  # Adjusted batch size
            "--nosmooth"  # Disable smoothing for consistency
        ]
        
        print(f"üé¨ Wav2Lip command: {' '.join(cmd)}")
        print(f"üéµ Audio duration: {audio_duration:.2f}s, FPS: {fps}, Batch size: {batch_size}")
        
        # Optimized environment
        env = os.environ.copy()
        env.update({
            "CUDA_VISIBLE_DEVICES": "0",
            "OMP_NUM_THREADS": "2",
            "MKL_NUM_THREADS": "2",
        })
        
        process = await asyncio.create_subprocess_exec(
            *cmd,
            cwd=wav2lip_dir,
            env=env,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE
        )
        
        stdout, stderr = await process.communicate()
        
        # Clean up avatar video
        if os.path.exists(avatar_video_path):
            os.remove(avatar_video_path)
        
        # Check if Wav2Lip completed successfully
        if process.returncode != 0:
            print(f"‚ùå Wav2Lip failed with return code {process.returncode}")
            print(f"‚ùå Wav2Lip stderr: {stderr.decode()}")
            raise Exception(f"Wav2Lip processing failed: {stderr.decode()}")
        
        # Verify output file exists and has content
        if not os.path.exists(output_path):
            print(f"‚ùå Wav2Lip output file not found: {output_path}")
            raise Exception("Wav2Lip output file not found")
        
        if os.path.getsize(output_path) < 1000:  # Less than 1KB
            print(f"‚ö†Ô∏è Wav2Lip output file too small: {os.path.getsize(output_path)} bytes")
            raise Exception("Wav2Lip output file too small")
        
        print(f"‚úÖ Wav2Lip completed successfully: {output_path}")
        
        # STEP 3: Fix video metadata to prevent looping issues
        fixed_output_path = await self._fix_video_metadata(output_path)
        
        return fixed_output_path
    
    async def _combine_videos_with_improved_sync(self, video_paths: List[str]) -> str:
        """Combine multiple videos with comprehensive debug logging"""
        if not video_paths:
            print("üîç [DEBUG] No video paths to combine")
            return ""
        
        if len(video_paths) == 1:
            print(f"üîç [DEBUG] Single video, no combination needed: {video_paths[0]}")
            return video_paths[0]
        
        try:
            print(f"üîç [DEBUG] Starting video combination: {len(video_paths)} videos")
            
            # Log all input videos with their details
            for i, path in enumerate(video_paths):
                if os.path.exists(path):
                    size = os.path.getsize(path)
                    duration = await self._get_audio_duration_fast(path)
                    print(f"üîç [DEBUG] Input video {i+1}: {path}")
                    print(f"   Size: {size:,} bytes, Duration: {duration:.3f}s")
                else:
                    print(f"‚ùå [DEBUG] Input video {i+1} not found: {path}")
            
            # Filter out invalid paths
            valid_paths = [path for path in video_paths if os.path.exists(path)]
            
            if not valid_paths:
                print(f"‚ùå [DEBUG] No valid video paths to combine")
                return ""
            
            print(f"üîç [DEBUG] Valid videos for combination: {len(valid_paths)}")
            
            # Generate output path
            combined_hash = hashlib.md5()
            for path in valid_paths:
                combined_hash.update(path.encode())
            cache_key = f"ultra_combined_{combined_hash.hexdigest()[:12]}"
            output_path = os.path.join("/tmp/wav2lip_ultra_outputs", f"{cache_key}.mp4")
            
            print(f"üîç [DEBUG] Output path: {output_path}")
            
            # Create concat file with detailed logging
            concat_file = f"/tmp/concat_{int(time.time())}.txt"
            print(f"üîç [DEBUG] Creating concat file: {concat_file}")
            
            with open(concat_file, 'w') as f:
                for i, video_path in enumerate(valid_paths):
                    f.write(f"file '{video_path}'\n")
                    print(f"üîç [DEBUG] Added to concat file: {video_path}")
            
            # Use concat demuxer with detailed logging
            cmd = [
                "ffmpeg",
                "-f", "concat",
                "-safe", "0",
                "-i", concat_file,
                "-c:v", "libx264",
                "-preset", "ultrafast",
                "-crf", "23",
                "-c:a", "aac",
                "-b:a", "128k",
                "-ar", "24000",
                "-movflags", "+faststart",
                output_path,
                "-y"
            ]
            
            print(f"üîç [DEBUG] Running FFmpeg command: {' '.join(cmd)}")
            
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            # Clean up concat file
            if os.path.exists(concat_file):
                os.remove(concat_file)
                print(f"üîç [DEBUG] Cleaned up concat file: {concat_file}")
            
            if result.returncode != 0:
                print(f"‚ùå [DEBUG] Video combination failed")
                print(f"‚ùå [DEBUG] FFmpeg stderr: {result.stderr}")
                return ""
            
            # Verify combined video
            if os.path.exists(output_path):
                combined_size = os.path.getsize(output_path)
                combined_duration = await self._get_audio_duration_fast(output_path)
                print(f"‚úÖ [DEBUG] Video combination completed successfully")
                print(f"   Output: {output_path}")
                print(f"   Size: {combined_size:,} bytes")
                print(f"   Duration: {combined_duration:.3f}s")
                
                # Calculate expected duration
                expected_duration = sum([await self._get_audio_duration_fast(path) for path in valid_paths])
                print(f"   Expected duration: {expected_duration:.3f}s")
                print(f"   Duration difference: {abs(combined_duration - expected_duration):.3f}s")
                
                if abs(combined_duration - expected_duration) > 0.5:
                    print(f"‚ö†Ô∏è [DEBUG] WARNING: Combined duration differs significantly from expected!")
            else:
                print(f"‚ùå [DEBUG] Combined video file not found: {output_path}")
                return ""
            
            # Fix metadata
            print(f"üîç [DEBUG] Fixing video metadata...")
            fixed_output_path = await self._fix_video_metadata(output_path)
            
            print(f"‚úÖ [DEBUG] Video combination and metadata fixing complete: {fixed_output_path}")
            return fixed_output_path
            
        except Exception as e:
            print(f"‚ùå [DEBUG] Error combining videos: {e}")
            import traceback
            print(f"‚ùå [DEBUG] Traceback: {traceback.format_exc()}")
            return ""
    
    async def _get_audio_duration_fast(self, audio_path: str) -> float:
        """Get audio duration with fast ffprobe"""
        try:
            cmd = [
                "ffprobe",
                "-v", "quiet",
                "-show_entries", "format=duration",
                "-of", "csv=p=0",
                audio_path
            ]
            
            process = await asyncio.create_subprocess_exec(
                *cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            
            stdout, stderr = await process.communicate()
            
            if process.returncode == 0:
                return float(stdout.decode().strip())
            else:
                return 10.0  # Default duration
                
        except Exception:
            return 10.0  # Default duration
    
    async def _prepare_audio_ultra_fast(self, audio_url: str) -> str:
        """Prepare audio with minimal processing"""
        if os.path.exists(audio_url):
            return audio_url
        else:
            # Download with minimal processing
            async with httpx.AsyncClient() as client:
                response = await client.get(audio_url)
                with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as f:
                    f.write(response.content)
                    return f.name
    
    async def _prepare_avatar_ultra_fast(self, agent_type: str) -> str:
        """Prepare avatar with minimal processing"""
        # Use absolute paths for Wav2Lip
        base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        avatar_images = {
            "general": os.path.join(base_dir, "avatars", "general.jpg"),
            "hotel": os.path.join(base_dir, "avatars", "hotel_receptionist.jpg"),
            "airport": os.path.join(base_dir, "avatars", "airport_assistant.jpg"),
            "sales": os.path.join(base_dir, "avatars", "sales_agent.jpg")
        }
        avatar_path = avatar_images.get(agent_type, avatar_images["general"])
        
        # Verify the avatar exists
        if not os.path.exists(avatar_path):
            print(f"‚ö†Ô∏è Avatar not found: {avatar_path}, using general")
            avatar_path = avatar_images["general"]
        
        return avatar_path
    
    def _get_audio_cache_key(self, text: str, agent_type: str) -> str:
        """Generate audio cache key"""
        content = f"{text}_{agent_type}_ultra_audio"
        return hashlib.md5(content.encode()).hexdigest()[:12]
    
    def _get_video_cache_key(self, audio_url: str, agent_type: str) -> str:
        """Generate video cache key"""
        content = f"{audio_url}_{agent_type}_ultra_video"
        return hashlib.md5(content.encode()).hexdigest()[:12]
    
    async def _check_audio_cache(self, cache_key: str) -> Optional[str]:
        """Check audio cache"""
        cache_file = os.path.join(self.cache_dir, f"{cache_key}.json")
        if os.path.exists(cache_file):
            try:
                with open(cache_file, 'r') as f:
                    cache_data = json.load(f)
                    audio_path = cache_data.get("audio_path")
                    if audio_path and os.path.exists(audio_path):
                        return audio_path
            except Exception:
                pass
        return None
    
    async def _check_video_cache(self, cache_key: str) -> Optional[str]:
        """Check video cache"""
        cache_file = os.path.join(self.cache_dir, f"{cache_key}.json")
        if os.path.exists(cache_file):
            try:
                with open(cache_file, 'r') as f:
                    cache_data = json.load(f)
                    video_path = cache_data.get("video_path")
                    if video_path and os.path.exists(video_path):
                        return video_path
            except Exception:
                pass
        return None
    
    async def _cache_audio(self, cache_key: str, audio_path: str):
        """Cache audio"""
        cache_file = os.path.join(self.cache_dir, f"{cache_key}.json")
        cache_data = {
            "audio_path": audio_path,
            "timestamp": time.time()
        }
        try:
            with open(cache_file, 'w') as f:
                json.dump(cache_data, f)
        except Exception:
            pass
    
    async def _cache_video(self, cache_key: str, video_path: str):
        """Cache video"""
        cache_file = os.path.join(self.cache_dir, f"{cache_key}.json")
        cache_data = {
            "video_path": video_path,
            "timestamp": time.time()
        }
        try:
            with open(cache_file, 'w') as f:
                json.dump(cache_data, f)
        except Exception:
            pass
    
    async def _convert_to_web_format(self, video_path: str) -> str:
        """Convert video to web format with comprehensive validation and metadata fixing"""
        if not video_path or not os.path.exists(video_path):
            return ""
        
        # STEP 1: Validate and fix video metadata to prevent playback issues
        fixed_video_path = await self._fix_video_metadata(video_path)
        
        # STEP 2: Add cache-busting timestamp to prevent browser caching issues
        timestamp = int(time.time())
        filename = os.path.basename(fixed_video_path)
        
        # Create web URL with cache-busting parameter
        web_url = f"http://localhost:8000/api/v1/videos/{filename}?t={timestamp}"
        
        print(f"‚úÖ Final video URL (with metadata fix): {web_url}")
        return web_url
    
    async def _fix_video_metadata(self, video_path: str) -> str:
        """Fix video metadata while preserving exact timing to prevent any gaps"""
        try:
            # Get original duration before fixing
            original_duration = await self._get_audio_duration_fast(video_path)
            
            # Create a new filename for the fixed video
            base_name = os.path.splitext(os.path.basename(video_path))[0]
            fixed_filename = f"{base_name}_fixed.mp4"
            fixed_path = os.path.join(os.path.dirname(video_path), fixed_filename)
            
            # Comprehensive FFmpeg command to fix metadata while preserving exact timing
            cmd = [
                "ffmpeg",
                "-i", video_path,
                "-c:v", "libx264",  # Re-encode video
                "-preset", "ultrafast",
                "-crf", "23",
                "-c:a", "aac",  # Re-encode audio
                "-b:a", "128k",
                "-ar", "24000",
                "-movflags", "+faststart",  # Optimize for web streaming
                "-avoid_negative_ts", "make_zero",  # Fix timestamp issues
                "-fflags", "+genpts",  # Generate proper timestamps
                "-async", "1",  # Audio sync correction
                "-vsync", "1",  # Video sync correction
                "-max_interleave_delta", "0",  # Better interleaving
                "-metadata", "title=VBVA Generated Video",  # Add metadata
                "-metadata", "artist=VBVA System",
                "-metadata", "comment=Generated by Video Based Virtual Assistant",
                "-metadata", "creation_time=now",  # Set creation time
                "-y",  # Overwrite output
                fixed_path
            ]
            
            print(f"[UltraFastProcessor] Fixing video metadata while preserving timing:")
            print(f"[UltraFastProcessor] Original duration: {original_duration:.3f}s")
            print(f"[UltraFastProcessor] Command: {' '.join(cmd)}")
            
            process = await asyncio.create_subprocess_exec(
                *cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            
            stdout, stderr = await process.communicate()
            
            if process.returncode != 0:
                print(f"‚ùå Video metadata fix failed: {stderr.decode()}")
                # Return original path if fix fails
                return video_path
            
            # Verify the fixed video exists and has content
            if not os.path.exists(fixed_path) or os.path.getsize(fixed_path) < 1000:
                print(f"‚ùå Fixed video validation failed: {fixed_path}")
                return video_path
            
            # CRITICAL: Verify timing is preserved
            fixed_duration = await self._get_audio_duration_fast(fixed_path)
            duration_diff = abs(fixed_duration - original_duration)
            
            print(f"üìä Fixed video duration: {fixed_duration:.3f}s")
            print(f"üìä Duration difference: {duration_diff:.3f}s")
            
            if duration_diff > 0.1:  # Allow only 100ms tolerance
                print(f"‚ùå CRITICAL: Metadata fix changed video duration! Original: {original_duration:.3f}s, Fixed: {fixed_duration:.3f}s")
                print(f"‚ùå Using original video to preserve timing")
                return video_path
            elif duration_diff > 0.01:  # Warn if difference is more than 10ms
                print(f"‚ö†Ô∏è Small duration change: {duration_diff:.3f}s (acceptable)")
            
            print(f"‚úÖ Video metadata fixed successfully: {fixed_path}")
            print(f"‚úÖ Timing preserved: {original_duration:.3f}s ‚Üí {fixed_duration:.3f}s")
            
            # Clean up original file if fix was successful
            if os.path.exists(video_path) and video_path != fixed_path:
                try:
                    os.remove(video_path)
                    print(f"üóëÔ∏è Cleaned up original video: {video_path}")
                except Exception as e:
                    print(f"‚ö†Ô∏è Could not clean up original video: {e}")
            
            return fixed_path
            
        except Exception as e:
            print(f"‚ùå Error fixing video metadata: {e}")
            return video_path
    
    def get_ultra_fast_status(self) -> Dict:
        """Get ultra-fast processing status"""
        return {
            "max_parallel_chunks": self.max_parallel_chunks,
            "optimal_chunk_duration": self.optimal_chunk_duration,
            "enable_preprocessing": self.enable_preprocessing,
            "enable_parallel_audio": self.enable_parallel_audio,
            "enable_memory_optimization": self.enable_memory_optimization,
            "enable_gpu_optimization": self.enable_gpu_optimization,
            "target_processing_time": "8.0 seconds",
            "speed_multiplier": "2x+ faster than baseline"
        }
    
    async def _validate_video_chunks(self, video_paths: List[str]) -> List[str]:
        """Validate video chunks and remove duplicates/invalid files"""
        if not video_paths:
            return []
        
        valid_paths = []
        seen_paths = set()
        
        for i, path in enumerate(video_paths):
            if not path:
                print(f"‚ö†Ô∏è Empty video path at index {i}, skipping")
                continue
                
            if path in seen_paths:
                print(f"‚ö†Ô∏è Duplicate video path detected at index {i}: {path}")
                continue
                
            if not os.path.exists(path):
                print(f"‚ö†Ô∏è Video path does not exist at index {i}: {path}")
                continue
                
            if os.path.getsize(path) < 1000:  # Less than 1KB is suspicious
                print(f"‚ö†Ô∏è Video file too small at index {i}: {path} ({os.path.getsize(path)} bytes)")
                continue
            
            seen_paths.add(path)
            valid_paths.append(path)
            print(f"‚úÖ Valid video chunk {i+1}: {path}")
        
        if len(valid_paths) != len(video_paths):
            print(f"‚ö†Ô∏è Removed {len(video_paths) - len(valid_paths)} invalid/duplicate video chunks")
        
        return valid_paths 